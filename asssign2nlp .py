# -*- coding: utf-8 -*-
"""Asssign2nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N7FyqaEMXDd9yCj169sMEd9gtgGym_Yq
"""

import pandas as pd
import numpy as np
import nltk
import re
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
import matplotlib.pyplot as plt
import random
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from string import punctuation
from keras.models import Model
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, Dropout, Conv1D, MaxPooling1D
from keras.layers import Embedding
from keras.utils.vis_utils import plot_model
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping
from sklearn.utils import class_weight
import keras
from keras import backend as K
from keras import utils
from keras.optimizers import Adam

dataset = pd.read_csv("https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv", header=0, delimiter="\t", quoting=3)

# Show the first ten rows of the dataset
dataset.head(10)

Sentiment_words=[]
for row in dataset['Sentiment']:
    if row ==0:
        Sentiment_words.append('negative')
    elif row == 1:
        Sentiment_words.append('neutral')
    elif row == 2:
        Sentiment_words.append('somewhat negative')
    elif row == 3:
        Sentiment_words.append('somewhat positive')
    elif row == 4:
        Sentiment_words.append('positive')
    else:
        Sentiment_words.append('Failed')
dataset['Sentiment_words'] = Sentiment_words

#MAking the word count
word_count=pd.value_counts(dataset['Sentiment_words'].values, sort=False)
word_count

#plotting the sentiments from the dataset
Index = [1,2,3,4,5]
plt.figure(figsize=(15,5))
plt.bar(Index,word_count,color = 'blue')
plt.xticks(Index,['negative','neutral','somewhat negative','somewhat positive','positive'],rotation=45)
plt.ylabel('word_count')
plt.xlabel('word')
plt.title('Count of Moods')
plt.bar(Index, word_count)
for a,b in zip(Index, word_count):
    plt.text(a, b, str(b) ,color='green', fontweight='bold')

def retrive_full_sentence(df):
  num_sentences=df["SentenceId"].max()
  full_sentences=[]
  num_full_sentences=0
  for i in range(df.shape[0]):
    if df['SentenceId'][i] > num_full_sentences:
      full_sentences.append((df['Phrase'][i], df['Sentiment'][i]))
      num_full_sentences = num_full_sentences + 1
  full_sentences_df=pd.DataFrame(full_sentences, columns=['Phrase', 'Sentiment'])    
  return full_sentences_df

fullsens=retrive_full_sentence(dataset)
X_train=dataset["Phrase"]
Y_train=dataset["Sentiment"]

#Converting the X_train and Y_train to array using numpy
X_train=np.array(X_train)
Y_train=np.array(Y_train)
X_train.shape
Y_train.shape

#Cleaning the text :removing stopwords, puncuation, and lemmatizing
def clean_text(df):
  clean_phrase=[]
  for n in range(len(df)):
    phrases=str(df[n])
    phrases=re.sub('[^a-zA-Z]',' ',phrases).lower().split()
    phrases=[WordNetLemmatizer().lemmatize(phrase) for phrase in phrases if not phrase in stopwords.words('english')]
    use_words=' '.join(phrases)
    clean_phrase.append(use_words)
  return clean_phrase

#Cleaning the training part for removal of unwanted words,lemmatizers and punctuations
clean_X=clean_text(X_train)

#Code for TF-IDF
x_train, x_test, y_train, y_test = train_test_split(clean_X,Y_train, test_size=0.3, random_state=2003)

class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)

max_feature = 2500
vectorizer = TfidfVectorizer(max_features=max_feature, min_df=4, max_df=0.8, ngram_range=(1,1))

x_train = vectorizer.fit_transform(x_train).toarray()
x_test = vectorizer.transform(x_test).toarray()

y_train = utils.to_categorical(y_train, 5)
y_test = utils.to_categorical(y_test, 5)

# Resahaping the inputs in order to match the requirement
x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)
x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)
x_train.shape
x_test.shape

#defining the functions for the Parameter Calculations
def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

#Creating The Model using Keras
model = Sequential(name='cnnMultiClassSentimentReg')

model.add(Conv1D(filters=64, kernel_size=3,activation='relu',input_shape=(2500,1)))
model.add(Conv1D(128, kernel_size=5, activation='relu'))
model.add(Conv1D(128, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(pool_size=1))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(5, activation='softmax'))

#Model Summary Architecture
model.summary()

#Initializing the Optimizer and Model Compile
optimizer=Adam(lr=1e-2)
model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy', recall_m, precision_m, f1_m])

# MOdel fitting with epochs and weights
history=model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_data=(x_test,y_test), class_weight=class_weights)

#Save the model for immediate use
model.save('1106925_1dconv_reg.h5')

from keras.models import load_model
#load the model for resuse
model = load_model('1106925_1dconv_reg.h5',custom_objects={'recall_m': recall_m,'precision_m': precision_m,'f1_m': f1_m})

#Evaluate the scores calculated
evaluate = model.evaluate(x_test, y_test, batch_size=128)
print('The testing accuracy is : ',evaluate[1])
print('Testing precision: ',evaluate[2])
print('Testing recall: ',evaluate[3])
print('Testing f1 score is: ', evaluate[4])

#Graph plot comparing the testing and training parameters 
x=range(0,15)

train_loss=history.history['loss']
test_acc=history.history['val_acc']
train_acc=history.history['acc']

test_f1=history.history['val_f1_m']
train_f1=history.history['f1_m']

test_recall=history.history['val_recall_m']
train_recall=history.history['recall_m']

test_prec=history.history['val_precision_m']
train_prec=history.history['precision_m']

plt.figure()
plt.plot(x, test_acc, 'r')
plt.plot(x, train_acc, 'g')
plt.title('Training and Testing Accuracy')
plt.legend(['test accuracy', 'train accuracy'])

plt.figure()
plt.plot(x, test_recall, 'r')
plt.plot(x, train_recall, 'g')
plt.title('Training and Testing Recall')
plt.legend(['test recall', 'train recall'])

plt.figure()
plt.plot(x, test_prec, 'r')
plt.plot(x, train_prec, 'g')
plt.title('Training and Testing Precision')
plt.legend(['test precision', 'train precision'])

plt.figure()
plt.plot(x, test_f1, 'r')
plt.plot(x, train_f1, 'g')
plt.title('Training and Testing F1')
plt.legend(['test f1', 'train f1'])